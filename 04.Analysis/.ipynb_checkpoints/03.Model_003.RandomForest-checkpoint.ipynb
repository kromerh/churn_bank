{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank customer churn prediction: MVP\n",
    "\n",
    "\n",
    "In this project, the overall goal is to predict the churn of bank customers. From a business perspective, this is very relevant for the effort to retain customers with the ultimate end goal of increasing profitability.\n",
    "\n",
    "Here in this notebook, a minimal viable product (MVP) is set up to investigate some models and generate a baseline to compare further modeling efforts to.\n",
    "\n",
    "Customer churn is defined as the percentage of customers that stopped using a company's product or service offering in a defined time frame. One might consider that customer churn is not so important as long as more new customers are acquired than lost to the company. This is fogetting entirely the cost of acquiring new customers. Bringing in new customers is a lot less profitable than retaining customers. In financial services, for example, a 5% increase in customer retention produces more than a 25% increase in profit (http://www2.bain.com/Images/BB_Prescription_cutting_costs.pdf). The reason for that is because returning customers spend on average more than already existing customers. In online services, a loyal customer spends on average 2/3 more than a new one (http://www2.bain.com/Images/Value_online_customer_loyalty_you_capture.pdf). At the same time there is a cost associated with acquiring new customers, which decreases when less new customers have to be acquired. Keeping existing customers thus allows for a reallocation of funds away from the need of growing by acquiring new customers. \n",
    "\n",
    "Customer churn can be reduced by pooling resources into keeping the most profitable customers, instead of focusing on keeping overall customer numbers (even unprofitable ones). Another option would be to find out why and when customers are leaving, thus targeting in a customer lifetime this specific point and put effort into avoiding churn. In either case, the customer churn has to be thoroughly analyzed, which is what this small example project is designed to deliver.\n",
    "\n",
    "## Outline\n",
    "\n",
    "This churn prediction project follows this outline:\n",
    "\n",
    "1. Dataset description\n",
    "2. Descriptive visualizations using Tableau\n",
    "3. Data extraction, transforming, and loading (ETL)\n",
    "4. **Analysis of the dataset**\n",
    "5. Visualization of the insights\n",
    "\n",
    "In this part of the project, stage 4 is covered. Stages 1 and 2 can be found here: http://heikokromer.com/index.php/2020/01/10/bank-customer-churn-prediction-identifying-the-question/'. \n",
    "\n",
    "\n",
    "Stage 3 can be found here: https://kyso.io/heiko/bank-customer-churn-prediction-etl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "\n",
    "In this part, following the previous investigation, a RandomForest will be used on the dataset for Churn prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "class Model_002():\n",
    "    \"\"\" Class for the Analysis part that contains all the methods\"\"\"\n",
    "    def __init__(self):\n",
    "        self.save_path_prepared = '../02.Prepared_data/'\n",
    "        \n",
    "    def load_data(self, fname):\n",
    "        \"\"\"\n",
    "        Reads and returns the dataset after the ETL process.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(f\"{self.save_path_prepared}/{fname}\", index_col=0)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def select_features(self, features, label_col, dataset):\n",
    "        \"\"\"\n",
    "        Selects the columns features (passed as list) from the dataset and returns this dataset. Returns also the labels, \n",
    "        the label_col must be passed.\n",
    "        \"\"\"\n",
    "        data_features = dataset[features]\n",
    "        data_labels = dataset[label_col]\n",
    "\n",
    "        return data_features, data_labels  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore  Age  Tenure    Balance  \\\n",
       "0          1    15634602  Hargrave          619   42       2       0.00   \n",
       "1          2    15647311      Hill          608   41       1   83807.86   \n",
       "2          3    15619304      Onio          502   42       8  159660.80   \n",
       "3          4    15701354      Boni          699   39       1       0.00   \n",
       "4          5    15737888  Mitchell          850   43       2  125510.82   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
       "0              1          1               1        101348.88       1   \n",
       "1              1          0               1        112542.58       0   \n",
       "2              3          1               0        113931.57       1   \n",
       "3              2          0               0         93826.63       0   \n",
       "4              1          1               1         79084.10       0   \n",
       "\n",
       "   Gender_Female  Gender_Male  Geography_France  Geography_Germany  \\\n",
       "0              1            0                 1                  0   \n",
       "1              1            0                 0                  0   \n",
       "2              1            0                 1                  0   \n",
       "3              1            0                 1                  0   \n",
       "4              1            0                 0                  0   \n",
       "\n",
       "   Geography_Spain  \n",
       "0                0  \n",
       "1                1  \n",
       "2                0  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FNAME = '2020-01-26.One_hot_encoded.csv'\n",
    "data = Model_002().load_data(FNAME)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (X, y): ((6000, 11), (6000,))\n",
      "Test set size (X, y): ((4000, 11), (4000,))\n"
     ]
    }
   ],
   "source": [
    "# Previous analysis found that something was wrong with EstimatedSalary\n",
    "# There are only two genders in this dataset, one column can be removed\n",
    "features = ['CreditScore',\n",
    " 'Age',\n",
    " 'Tenure',\n",
    " 'Balance',\n",
    " 'NumOfProducts',\n",
    " 'HasCrCard',\n",
    " 'IsActiveMember',\n",
    " 'Gender_Female',\n",
    " 'Geography_France',\n",
    " 'Geography_Germany',\n",
    " 'Geography_Spain']\n",
    "\n",
    "label_col = 'Exited'\n",
    "\n",
    "X, y = Model_002().select_features(features, label_col, data)\n",
    "\n",
    "fraction_train = 0.6\n",
    "fraction_test = 0.4\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=fraction_test, random_state=random_state)\n",
    "\n",
    "print(f\"Training set size (X, y): {X_train.shape, y_train.shape}\")\n",
    "print(f\"Test set size (X, y): {X_test.shape, y_test.shape}\")\n",
    "\n",
    "# QA on number of cols\n",
    "assert X_train.shape[1] == X_test.shape[1]\n",
    "\n",
    "# QA on number of rows total\n",
    "assert X_train.shape[0] + X_test.shape[0] == X.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building blocks for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance']\n",
    "categorical_cols = ['NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Gender_Female', 'Geography_France', 'Geography_Germany', 'Geography_Spain']\n",
    "\n",
    "# numerical feature scaling\n",
    "\n",
    "# min max scaler standard\n",
    "mms_std = Pipeline(steps=[\n",
    "        ('minmax', MinMaxScaler(feature_range=(0, 1)))])\n",
    "\n",
    "# min max scaler -1 to 1\n",
    "mms_minus1 = Pipeline(steps=[\n",
    "        ('minmax', MinMaxScaler(feature_range=(-1, 1)))])\n",
    "\n",
    "# standard scaler standard\n",
    "ss = Pipeline(steps=[\n",
    "        ('standard', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min max scaler standard, feature range 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', mms_std, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__n_estimators': 300,\n",
       " 'classifier__min_samples_split': 10,\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__max_features': 'sqrt',\n",
       " 'classifier__max_depth': 60,\n",
       " 'classifier__bootstrap': True}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = [{'classifier__n_estimators': n_estimators,\n",
    "               'classifier__max_features': max_features,\n",
    "               'classifier__max_depth': max_depth,\n",
    "               'classifier__min_samples_split': min_samples_split,\n",
    "               'classifier__min_samples_leaf': min_samples_leaf,\n",
    "               'classifier__bootstrap': bootstrap}]\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=pipe, param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   55.5s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 486 out of 486 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hpyerparameters :(best parameters)  {'classifier__bootstrap': True, 'classifier__max_depth': 50, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 3, 'classifier__min_samples_split': 12, 'classifier__n_estimators': 300}\n",
      "Best score (refit key) : 0.8595374245001812\n"
     ]
    }
   ],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [200, 300, 500],\n",
    "    'classifier__min_samples_split': [8, 10, 12],\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__max_features': ['sqrt', 'auto'],\n",
    "    'classifier__max_depth': [50, 60, 70],\n",
    "    'classifier__bootstrap': [True]\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2,  scoring=scoring, refit='AUC', return_train_score=True)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "results = rf_cv.cv_results_\n",
    "print(\"Tuned hpyerparameters :(best parameters) \", rf_cv.best_params_)\n",
    "print(\"Best score (refit key) :\", rf_cv.best_score_)\n",
    "rf_optimized = rf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for RandomForestClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Stayed       0.88      0.97      0.92      3190\n",
      "      Exited       0.78      0.47      0.59       810\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.83      0.72      0.75      4000\n",
      "weighted avg       0.86      0.87      0.85      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for RandomForestClassifier:\")\n",
    "rf_predicted_test = rf_optimized.predict(X_test)\n",
    "clf_report = classification_report(y_test, rf_predicted_test, target_names=['Stayed', 'Exited'])\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] find a way to get the precision, recall and so on better and store these values in a dictionary\n",
    "- [ ] repeat the process for the other scalers\n",
    "- [ ] make a feature importance plot\n",
    "- [ ] write some conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
